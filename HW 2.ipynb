{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fb70f4b",
   "metadata": {},
   "source": [
    "# INFO 5390 HW 2\n",
    "**Ruth Rajcoomar (rr672)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9222ac0",
   "metadata": {},
   "source": [
    "## Part A: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16328830",
   "metadata": {},
   "source": [
    "_Data Collection Process:_ I am using data from the Common Voice Datasets, which are free datasets made available by the Mozilla Foundation (Mozilla). Volunteers write sentences, which are then spoken by other volunteers. Separate volunteers then review the recordings to upvote or downvote them. Mozilla asks volunteers to provide demographic data about themselves as well. Project decisions are made \"by a diverse community of activists, linguists, data scientists, academics and software engineers from all over the world.\" From the Mozilla Common Voices datasets, I am specifically using part of the Common Voice Delta Segment 16.1 dataset which was published on 1/4/2024. This data only consists of new data added between the releases of Common Voice Corpus 15.0 and Common Voice Corpus 16.1. I am using data from the validated clips.\n",
    "\n",
    "_Data Attributes:_ Attributes of this dataset include: client_id (an identifier for the person contributing their voice), path (the name of the audio file), sentence (the sequence of words spoken by the person; the 'ground truth'), up_votes (the number of people who reviewed a clip and could hear and understand the speaker), down_votes (the number of people who reviewed a clip and could not hear or understand the speaker), age (age group in buckets of tens), gender (male, female, or other), accents (any way of pronouncing words that may depend on factors like location or social class). \n",
    "\n",
    "_API Being Tested:_ I am testing the SpeechServices API from Microsoft Azure. Microsofft claims that this API can transcribe speech to text with high accuracy. However, they do note that if the audio contains ambient noise or domain-specific jargon, the model may not be sufficient as is.\n",
    "\n",
    "_Motivation:_ I chose this specific dataset primarily because the corpus datasets are too large for me to download. (However, the dataset I did download was also large. I chose to take a sample from this dataset that had an equal number of audio files from each age group, as I want to look at how age affects the API performance. See the appendix for more details.) This is due to constraints such as limited free access to APIs and my internet speed. The Delta Segment 16.1 is also a good choice because it is the most recent Delta Segment, which means it contains the most updated data attributes and will be reflective of the most up to data instructions Mozilla gave its volunteers. Therefore, this dataset is likely to be of high quality. Also, the validated clips are confirmed audible and understandable by human volunteers. I used Microsoft services for the API as it was recommended in the instructions as not requiring credit card information. In addition, Microsoft is a large company with many resources, so I expect that they would put significant effort into making a high quality API. The most relevant attributes for my analyses were: path, sentence, and age. \n",
    "\n",
    "_Hypothesis:_ The API will perform well on younger people (specifically those in their teens, twenties, thirties, fourties) and underperform on older people (specifically those in their fifites, sixties, seventies).\n",
    "\n",
    "_Other Background Information:_ Attributes such as age, gender, and accents are self-reported. Age was easier to work with in terms of being measurable, as people chose from a list of prepared options without the ability to create their own option. (This is also the case for gender, which I have chosen not to look at for the purposes of this homework.) I originally wanted to work with accents, but found that since people could type in accents in addition to selecting from prepared options, it was harder to work with in terms of measurability.\n",
    "My submitted materials are as follows: this Jupyter Notebook, a folder titled edited_data (which has the actual data I used for this assignment), and a folder titled cv-corpus-16.1-delta-2023-12-06 which is the original data from Mozilla."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d56348",
   "metadata": {},
   "source": [
    "## Part B: Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c262acda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8a42c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Microsoft Azure Speech Service API\n",
    "subscription_key = \"a9b0c545d9cb43e686da72a76bc01c87\"\n",
    "region = \"eastus\"\n",
    "\n",
    "azure_api = speechsdk.SpeechConfig(subscription=subscription_key, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ea4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "voices_df = pd.read_csv('/Users/ruthrajcoomar/Documents/info5390/HW2_rr672/edited_data/common_voices_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ce4336e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'common_voice_en_38667654.wav': 'That place is facing erosion.', 'common_voice_en_38571925.wav': 'Several popular movies and television programs have been filmed in Ketanyang.', 'common_voice_en_38607162.wav': 'This in turn will produce radicals to destroy harmful contaminants.', 'common_voice_en_39175731.wav': 'Triang Walker coonhounds get along well with other dogs and with children.', 'common_voice_en_38607213.wav': 'How many people work here?', 'common_voice_en_38522174.wav': \"The team's average attendance ranked 6th in the seven team league.\", 'common_voice_en_38539226.wav': 'Several of these canals are still in use today.', 'common_voice_en_38916560.wav': 'The building was designed by Elliott Woods.', 'common_voice_en_38667569.wav': 'The river upstream of the Bay supports populations of salmon, steelhead and cutthroat trout.', 'common_voice_en_38778689.wav': 'Tsunami starred as Escamillo and Carmen Disrupted with Sharon Stone.', 'common_voice_en_39018435.wav': 'He then passes the daily operations to local leadership for the long term.', 'common_voice_en_38528159.wav': \"In C, the associativity is left to right for most operators. In Seashell it's right to left.\", 'common_voice_en_38519192.wav': 'It is also used for many purposes on Wikimedia Foundation projects.', 'common_voice_en_38763709.wav': \"Another great source of revenue was Lunar Storm's cooperation with other companies.\", 'common_voice_en_38677972.wav': 'However, cases such as graphene may provide counter examples.', 'common_voice_en_38495794.wav': 'Nick Ferrant recalls action sure to elicit the required response.', 'common_voice_en_38763666.wav': 'El Salva is also used by dentists following extraction of a maxillary molar tooth.', 'common_voice_en_38516685.wav': 'The historically listed Totem Theatre, created for the entertainment of this camp, still exists today.', 'common_voice_en_39436319.wav': 'It refers to the closely packed berries the species produce.', 'common_voice_en_38706229.wav': 'Its soundtrack was written by a claimed composer, Jose Cochiro.', 'common_voice_en_38825214.wav': 'The maintenance originated with the leaders of the South governing colonies of the British Empire.', 'common_voice_en_38523203.wav': '', 'common_voice_en_38557227.wav': '', 'common_voice_en_38743374.wav': '', 'common_voice_en_38536394.wav': '', 'common_voice_en_38512587.wav': '', 'common_voice_en_38763675.wav': '', 'common_voice_en_38510796.wav': '', 'common_voice_en_38623695.wav': \"His cartoons are featured on the newspaper's website.\", 'common_voice_en_38687232.wav': 'The latter race has occurred as a vagrant to Granada.', 'common_voice_en_38572985.wav': 'Due to the power outage, the telemetry log data was faulty.', 'common_voice_en_38774035.wav': 'A majority of the Russian delegates followed them out of the hall.', 'common_voice_en_38648108.wav': 'Some of the stones have survived to the present.', 'common_voice_en_38740608.wav': 'She became secretary of the chamber.', 'common_voice_en_38824806.wav': 'He no longer represents anything particularly British or even modern.'}\n"
     ]
    }
   ],
   "source": [
    "# Store file names and generated transcriptions from API into dictionary\n",
    "audio_folder = '/Users/ruthrajcoomar/Documents/info5390/HW2_rr672/edited_data/wav_files'\n",
    "transcription_dict = {}\n",
    "for filename in os.listdir(audio_folder):\n",
    "    # Call API to generate desired output\n",
    "    audio_path = os.path.join(audio_folder, filename)\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=audio_path)\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=azure_api, audio_config=audio_config)\n",
    "    result = speech_recognizer.recognize_once()\n",
    "    # Store result of API in dictionary\n",
    "    transcription_dict[filename] = result.text\n",
    "\n",
    "# Print the resulting dictionary\n",
    "print(transcription_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675a8395",
   "metadata": {},
   "source": [
    "## Part C: Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bac1901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Mean WER: 32.17%\n",
      "Overall Mean CER: 23.14%\n",
      "\n",
      "Mean WER of people in their teens: 45.05%\n",
      "Mean WER of people in their twenties: 42.40%\n",
      "Mean WER of people in their thirties: 45.33%\n",
      "Mean WER of people in their fourties: 20.00%\n",
      "Mean WER of people in their fifties: 2.86%\n",
      "Mean WER of people in their sixties: 34.16%\n",
      "Mean WER of people in their seventies: 35.38%\n",
      "\n",
      "Mean CER of people in their teens: 25.20%\n",
      "Mean CER of people in their twenties: 26.26%\n",
      "Mean CER of people in their thirties: 41.15%\n",
      "Mean CER of people in their fourties: 20.00%\n",
      "Mean CER of people in their fifties: 0.43%\n",
      "Mean CER of people in their sixties: 23.88%\n",
      "Mean CER of people in their seventies: 25.07%\n"
     ]
    }
   ],
   "source": [
    "# Convert API output dictionary into one dataframe\n",
    "transcription_df = pd.DataFrame.from_dict(transcription_dict, orient='index', columns=['transcription'])\n",
    "\n",
    "# Merge to dataframe containing 'ground truth'\n",
    "merged_df = pd.merge(voices_df, transcription_df, left_on=\"path\", right_index=True, how=\"left\")\n",
    "# 'ground truths' are in the 'sentence' column of voices_df\n",
    "\n",
    "# Compare API outputs to 'ground truth' for each row\n",
    "# Using Word Error Rate (WER)\n",
    "merged_df['wer'] = merged_df.apply(lambda row: jiwer.wer(row['sentence'], row['transcription']), axis=1)\n",
    "# Using Character Error Rate (CER)\n",
    "merged_df['cer'] = merged_df.apply(lambda row: jiwer.cer(row['sentence'], row['transcription']), axis=1)\n",
    "\n",
    "# Aggregation statistics\n",
    "age_order_mapping = {\n",
    "    'teens': 1,\n",
    "    'twenties': 2,\n",
    "    'thirties': 3,\n",
    "    'fourties': 4,\n",
    "    'fifties': 5,\n",
    "    'sixties': 6,\n",
    "    'seventies': 7\n",
    "}\n",
    "# Overall WER and CER\n",
    "mean_wer = merged_df['wer'].mean()\n",
    "print(f\"Overall Mean WER: {mean_wer:.2%}\")\n",
    "mean_cer = merged_df['cer'].mean()\n",
    "print(f\"Overall Mean CER: {mean_cer:.2%}\")\n",
    "print()\n",
    "# WER by age\n",
    "mean_wer_by_age = merged_df.groupby('age')['wer'].mean()\n",
    "sorted_mean_wer_by_age = sorted(mean_wer_by_age.items(), key=lambda x: age_order_mapping.get(x[0]))\n",
    "for age, mean_wer in sorted_mean_wer_by_age:\n",
    "    print(f\"Mean WER of people in their {age}: {mean_wer:.2%}\")\n",
    "print()\n",
    "# CER by age\n",
    "mean_cer_by_age = merged_df.groupby('age')['cer'].mean()\n",
    "sorted_mean_cer_by_age = sorted(mean_cer_by_age.items(), key=lambda x: age_order_mapping.get(x[0]))\n",
    "for age, mean_cer in sorted_mean_cer_by_age:\n",
    "    print(f\"Mean CER of people in their {age}: {mean_cer:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea72e17c",
   "metadata": {},
   "source": [
    "## Part D: Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6fdc09",
   "metadata": {},
   "source": [
    "_Explanation of Analysis:_ I first merged the transcriptions (the results from the Microsoft Azure SpeechServices API) to my voices_df dataframe which contained the ground truths (in the `sentence` column). For each audio file, I compared the API outputs to the ground truth using two metrics: Word Error Rate (WER) and Character Error Rate (CER). To present these metrics, I obtained the mean WER and CER across all audio files. I also presented the mean WER and CER for each age group accounted for in the dataset (teens, twenties, thirties, fourties, fifities, sixties, seventies).\n",
    "\n",
    "_Ground Truths:_ I did not choose the ground truths myself in this case. The relevant ground truths (i.e. the sequence of words spoken by the person) was provided by Mozilla as part of the dataset in the `sentence` column. I spot checked by listening to a few of the audio files, and they matched the words in the `sentence` column. In addition to that, Mozilla has robust quality control guidelines so I was not worried about the accuracy of their ground truths.\n",
    "\n",
    "_Metrics:_ I chose Word Error Rate (WER) and Character Error Rate (CER) as they are popular and widely utilized in general transcription cases according to the literature. These sentences did not require any special treatment, as Mozilla intends for them to be natural and conversational. Utilizing the mean for WER and CER allows for an overall, general assessment of the API's performance. It also provides a solid lauching point for determining if further, more detailed analyses would be worth the time and effort.\n",
    "\n",
    "_Takeaways:_ My hypothesis (The API will perform well on younger people (specifically those in their teens, twenties, thirties, fourties) and underperform on older people (specifically those in their fifites, sixties, seventies).) did not hold up after this audit. \n",
    "- The mean WER for people in their teens, twenties, and thirties was higher than the overall mean WER.\n",
    "- The mean WER for people in their fourties and fifties was lower than the overall mean WER.\n",
    "- The mean WER for people in their sixties and seventies was higher than the overall mean WER.\n",
    "- The mean CER for people in their teens, twenties, and thirties was higher than the overall mean CER.\n",
    "- The mean CER for people in their fourties and fifties was lower than the overall mean CER.\n",
    "- The mean CER for people in their sixties and seventies was higher than the overall mean CER.\n",
    "Overall, the API performed better than the overall mean on people in their fourties and fifties and worse than the overall mean for all other age groups, regardless of whether the chosen metric is WER or CER. \n",
    "It's possible that the sample of people in their fourties and fifites had accents that the model trained on more. It is also possible that the training data was biased towards these age groups. Cognititve factors such as difficulty in articulation could apply to those in their sixities or seventies, giving the API difficulty. Background noise could have been a distorting factor for any age group, those these audio clips were reviewed as being audible by humans. The big takeaway here is that it is important to have a dataset that is representative across many demographic features such as age in order to have fairer algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90f7dde",
   "metadata": {},
   "source": [
    "## Part E: Sources\n",
    "\n",
    "### Introduction\n",
    "- https://commonvoice.mozilla.org/en/datasets\n",
    "- https://commonvoice.mozilla.org/en/about?tab=how-validate#playbook\n",
    "- https://learn.microsoft.com/en-us/azure/ai-services/speech-service/overview\n",
    "- https://discourse.mozilla.org/t/delta-releases/106567\n",
    "\n",
    "### Setting Up and Initalizing API\n",
    "\n",
    "- https://learn.microsoft.com/en-us/azure/ai-services/speech-service/get-started-speech-to-text?tabs=macos%2Cterminal&pivots=programming-language-python\n",
    "- https://learn.microsoft.com/en-us/javascript/api/microsoft-cognitiveservices-speech-sdk/speechconfig?view=azure-node-latest\n",
    "\n",
    "### Generating Text Transcriptions\n",
    "- https://learn.microsoft.com/en-us/azure/ai-services/speech-service/batch-transcription\n",
    "- https://stackoverflow.com/questions/56884243/tutorial-for-azure-speech-to-text\n",
    "- https://learn.microsoft.com/en-us/azure/ai-services/speech-service/get-started-speech-to-text?tabs=macos%2Cterminal&pivots=programming-language-python\n",
    "\n",
    "### Analyzing Output\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.from_dict.html\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html\n",
    "- https://pypi.org/project/jiwer/\n",
    "\n",
    "### Observations\n",
    "- https://commonvoice.mozilla.org/en/guidelines?tab=sentence\n",
    "- https://huggingface.co/learn/audio-course/en/chapter5/evaluation\n",
    "- https://rechtsprechung-im-ostseeraum.archiv.uni-greifswald.de/word-error-rate-character-error-rate-how-to-evaluate-a-model/\n",
    "\n",
    "### Appendix\n",
    "- https://podcastle.ai/converter/mp3-to-wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5b9f00",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ecbfe3",
   "metadata": {},
   "source": [
    "The code block below shows the process I utilized in order to obtain a sample from the original dataset, with the goal of having an equal number of audio files from each age group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d4659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original TSV file\n",
    "tsv_file_path = '/Users/ruthrajcoomar/Documents/info5390/HW2_rr672/cv-corpus-16.1-delta-2023-12-06/en/validated.tsv'\n",
    "df = pd.read_csv(tsv_file_path, delimiter='\\t')\n",
    "# Make groups of ages\n",
    "sample_df = df.groupby('age').sample(n=5, random_state=4)\n",
    "# Change format given in string from mp3 to wav\n",
    "def change_extension(filename):\n",
    "    return filename.replace('.mp3', '.wav')\n",
    "sample_df['path'] = sample_df['path'].apply(change_extension)\n",
    "# Save sample as CSV file\n",
    "sample_df.to_csv('common_voices_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1da22f",
   "metadata": {},
   "source": [
    "I manually copied the mp3 files with names matching the ones in the common_voices_clean.csv file into the `needed_mp3_files` folder within the `edited_data` folder. I then converted each mp3 file to wav files using podcastle.ai, and manually compiled the wav files into the `wav_files` folder within the `edited_data` folder. I researched processes for performing these processes programatically, but ran into many errors. It got to the point where my time was better served doing these actions manually so I could focus on being efficient with the code most directly relevant to the homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4f1fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
